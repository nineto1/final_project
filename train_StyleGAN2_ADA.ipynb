{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_StyleGAN2_ADA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "C3SmqtGYel7X"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nineto1/final_project/blob/main/train_StyleGAN2_ADA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Clone 'StyleGAN2-ADA' Repository and go inside the directory"
      ],
      "metadata": {
        "id": "SwNqE2S3VbPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Colab 에서 GPU를 할당받아 사용하고 있는지 확인"
      ],
      "metadata": {
        "id": "ApCdBppoZOk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPVM0lViZDdv",
        "outputId": "2d0ac9fb-7464-4c6f-cc6f-e8398c881538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 16 05:49:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- StyleGAN2-ADA는 Tensorflow 2.x 버전을 지원하지 않습니다. 따라서 Tensorflow 1.X 버전을 사용하도록 설정해주어야 합니다."
      ],
      "metadata": {
        "id": "E-BRhiCTZi8U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmSdtm6pVVDw",
        "outputId": "f1b073d2-ca48-4a1a-a6c1-3d13b98d07e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow 2.x is not supported in 'StyleGAN2-ADA'\n",
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone 'StyleGAN2-ADA'\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada.git\n",
        "%cd /content/stylegan2-ada"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5sfK-rfV2xm",
        "outputId": "b6e9c133-12f1-4496-d67a-ed6ce96e78c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2-ada'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 74 (delta 0), reused 1 (delta 0), pack-reused 71\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n",
            "/content/stylegan2-ada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preparing Dataset\n"
      ],
      "metadata": {
        "id": "7YTdT2-E-Hzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Mounted Google drive"
      ],
      "metadata": {
        "id": "ft7yEwcLWf4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounted Google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smqMvhzIWEbk",
        "outputId": "3ae18ae2-9b43-4a93-822e-da1f144beece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Convert our dataset(IMAGE) to '.tfrecords' format\n",
        "  - 원본 이미지 파일이 '.jpg' 형태로 저장되어 있기 때문에, Tensorflow에서 활용할 수 있도록 '.tfrecords' 형태로 변환하여 줍니다."
      ],
      "metadata": {
        "id": "JccI8W4ZWlNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load own dataset from google drive\n",
        "# path = {구글 드라이브 내 데이터셋 경로}\n",
        "path = \"/content/drive/MyDrive/styleGAN/celeb_face\"\n",
        "\n",
        "path_dataset = \"./dataset/Img\" # .tfrecords 파일이 저장될 경로"
      ],
      "metadata": {
        "id": "7W1zNujlWzZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python dataset_tool.py create_from_images {path_dataset} {path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DafCBynWa8tX",
        "outputId": "a1c7c4db-9296-4ff6-cb19-7ec5c660294c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images from \"/content/drive/MyDrive/styleGAN/celeb_face\"\n",
            "Creating dataset \"./dataset/Img\"\n",
            "dataset_tool.py:96: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
            "Added 9773 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {path_dataset}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFJsqpcpcBqW",
        "outputId": "f5afc844-c470-4e07-bc84-e1f8e31fd922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Img-r02.tfrecords  Img-r04.tfrecords  Img-r06.tfrecords  Img-r08.tfrecords\n",
            "Img-r03.tfrecords  Img-r05.tfrecords  Img-r07.tfrecords  Img-r09.tfrecords\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Training StyleGAN2-ADA"
      ],
      "metadata": {
        "id": "GFjivmjQcLsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'StyleGAN2-ADA' 는 NVIDIA의 'NVlabs'라는 github를 통해 배포되어 있으며,\n",
        "'FFHQ' 비롯한 고화질 이미지로 구성한 다양한 데이터셋을 학습시킨 사전 모델을 제공하고 있습니다.\n",
        "(https://github.com/NVlabs/stylegan2-ada#external-data-repository)"
      ],
      "metadata": {
        "id": "IF4YdNUecWCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Pretrained model\n",
        "!wget https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sJgoasKeHRc",
        "outputId": "685d1c85-c2b6-480b-dd51-72dd72f31686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-16 06:06:48--  https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\n",
            "Resolving nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)... 52.222.174.129, 52.222.174.55, 52.222.174.17, ...\n",
            "Connecting to nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)|52.222.174.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381646055 (364M) [binary/octet-stream]\n",
            "Saving to: ‘ffhq.pkl’\n",
            "\n",
            "ffhq.pkl            100%[===================>] 363.97M  69.6MB/s    in 5.2s    \n",
            "\n",
            "2022-01-16 06:06:54 (69.4 MB/s) - ‘ffhq.pkl’ saved [381646055/381646055]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습은 `'train.py'`라는 파일을 사용해 진행할수 있으며, 사용법에 대한 설명 다음과 같습니다."
      ],
      "metadata": {
        "id": "C3SmqtGYel7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHXH479PehRv",
        "outputId": "1076bcfd-c071-4c72-a745-2cd6c6dc2737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: train.py [-h] --outdir DIR [--gpus INT] [--snap INT] [--seed INT] [-n]\n",
            "                --data PATH [--res INT] [--mirror BOOL] [--metrics LIST]\n",
            "                [--metricdata PATH]\n",
            "                [--cfg {auto,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline}]\n",
            "                [--gamma FLOAT] [--kimg INT] [--aug {noaug,ada,fixed,adarv}]\n",
            "                [--p FLOAT] [--target TARGET]\n",
            "                [--augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}]\n",
            "                [--cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}]\n",
            "                [--dcap FLOAT] [--resume RESUME] [--freezed INT]\n",
            "\n",
            "Train a GAN using the techniques described in the paper\n",
            "\"Training Generative Adversarial Networks with Limited Data\".\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "\n",
            "general options:\n",
            "  --outdir DIR          Where to save the results (required)\n",
            "  --gpus INT            Number of GPUs to use (default: 1 gpu)\n",
            "  --snap INT            Snapshot interval (default: 50 ticks)\n",
            "  --seed INT            Random seed (default: 1000)\n",
            "  -n, --dry-run         Print training options and exit\n",
            "\n",
            "training dataset:\n",
            "  --data PATH           Training dataset path (required)\n",
            "  --res INT             Dataset resolution (default: highest available)\n",
            "  --mirror BOOL         Augment dataset with x-flips (default: false)\n",
            "\n",
            "metrics:\n",
            "  --metrics LIST        Comma-separated list or \"none\" (default: fid50k_full)\n",
            "  --metricdata PATH     Dataset to evaluate metrics against (optional)\n",
            "\n",
            "base config:\n",
            "  --cfg {auto,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline}\n",
            "                        Base config (default: auto)\n",
            "  --gamma FLOAT         Override R1 gamma\n",
            "  --kimg INT            Override training duration\n",
            "\n",
            "discriminator augmentation:\n",
            "  --aug {noaug,ada,fixed,adarv}\n",
            "                        Augmentation mode (default: ada)\n",
            "  --p FLOAT             Specify augmentation probability for --aug=fixed\n",
            "  --target TARGET       Override ADA target for --aug=ada and --aug=adarv\n",
            "  --augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}\n",
            "                        Augmentation pipeline (default: bgc)\n",
            "\n",
            "comparison methods:\n",
            "  --cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}\n",
            "                        Comparison method (default: nocmethod)\n",
            "  --dcap FLOAT          Multiplier for discriminator capacity\n",
            "\n",
            "transfer learning:\n",
            "  --resume RESUME       Resume from network pickle (default: noresume)\n",
            "  --freezed INT         Freeze-D (default: 0 discriminator layers)\n",
            "\n",
            "examples:\n",
            "\n",
            "  # Train custom dataset using 1 GPU.\n",
            "  python train.py --outdir=~/training-runs --gpus=1 --data=~/datasets/custom\n",
            "\n",
            "  # Train class-conditional CIFAR-10 using 2 GPUs.\n",
            "  python train.py --outdir=~/training-runs --gpus=2 --data=~/datasets/cifar10c \\\n",
            "      --cfg=cifar\n",
            "\n",
            "  # Transfer learn MetFaces from FFHQ using 4 GPUs.\n",
            "  python train.py --outdir=~/training-runs --gpus=4 --data=~/datasets/metfaces \\\n",
            "      --cfg=paper1024 --mirror=1 --resume=ffhq1024 --snap=10\n",
            "\n",
            "  # Reproduce original StyleGAN2 config F.\n",
            "  python train.py --outdir=~/training-runs --gpus=8 --data=~/datasets/ffhq \\\n",
            "      --cfg=stylegan2 --res=1024 --mirror=1 --aug=noaug\n",
            "\n",
            "available base configs (--cfg):\n",
            "  auto           Automatically select reasonable defaults based on resolution\n",
            "                 and GPU count. Good starting point for new datasets.\n",
            "  stylegan2      Reproduce results for StyleGAN2 config F at 1024x1024.\n",
            "  paper256       Reproduce results for FFHQ and LSUN Cat at 256x256.\n",
            "  paper512       Reproduce results for BreCaHAD and AFHQ at 512x512.\n",
            "  paper1024      Reproduce results for MetFaces at 1024x1024.\n",
            "  cifar          Reproduce results for CIFAR-10 (tuned configuration).\n",
            "  cifarbaseline  Reproduce results for CIFAR-10 (baseline configuration).\n",
            "\n",
            "transfer learning source networks (--resume):\n",
            "  ffhq256        FFHQ trained at 256x256 resolution.\n",
            "  ffhq512        FFHQ trained at 512x512 resolution.\n",
            "  ffhq1024       FFHQ trained at 1024x1024 resolution.\n",
            "  celebahq256    CelebA-HQ trained at 256x256 resolution.\n",
            "  lsundog256     LSUN Dog trained at 256x256 resolution.\n",
            "  <path or URL>  Custom network pickle.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "sCWUcSQlf_Ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H24HN4iiLiQ",
        "outputId": "287bbd4e-962b-4fb8-8694-c0cce215737d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2-ada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outdir = \"/content/drive/MyDrive/styleGAN/result\" # 생성된 모델이 저장될 경로\n",
        "\n",
        "snap = 10 # 스냅샷 생성 주기('ticks'라는 회수에 기반)\n",
        "\n",
        "res = 512 # 생성될 이미지의 기준 픽셀 수\n",
        "\n",
        "kimg = 10000 # 훈련 (이미지) 길이 정의\n",
        "\n",
        "augpipe = \"bgcfnc\" # 이미지 확대 방식 조정('blit', 'geom', 'color', 'filter', 'noise', 'cutout' or 이들의 조합)\n",
        "\n",
        "# metrics = None # 어떤 평가 기준을 사용하여 성능을 측정할 지 정의 (default : fid50k_full)\n",
        "\n",
        "\"\"\"\n",
        "# 사전 모델의 경로를 정의, 중도에 끊기더라도 아래와 같이 생성된 모델의 경로를 대입하여, 모델 학습을 이어서 진행할 수 있습니다.\n",
        "resume = \"/content/drive/MyDrive/styleGAN/result/00002-Img-res512-auto1-bgcfnc-resumecustom/network-snapshot-000240.pkl\"\n",
        "\"\"\"\n",
        "resume = \"ffhq.pkl\""
      ],
      "metadata": {
        "id": "lc2SW-_wghVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --outdir={outdir} --snap={snap} --data={path_dataset} \\\n",
        "--augpipe={augpipe} --res={res} --kimg={kimg} --resume={resume}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFE68v4tghGW",
        "outputId": "ca0163ad-6441-4c5d-f548-62bc0e6f788a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 4294967296 bytes == 0x5611dafae000 @  0x7fd014616001 0x7fd01185954f 0x7fd0118a9b58 0x7fd0118adb17 0x7fd01194c203 0x5611d2fc2544 0x5611d2fc2240 0x5611d3036627 0x5611d3030ced 0x5611d2fc448c 0x5611d3005159 0x5611d30020a4 0x5611d2fc2d49 0x5611d303694f 0x5611d30309ee 0x5611d2f02e2b 0x5611d3032fe4 0x5611d30309ee 0x5611d2f02e2b 0x5611d3032fe4 0x5611d3030ced 0x5611d2f02e2b 0x5611d3032fe4 0x5611d2fc3afa 0x5611d3031915 0x5611d30309ee 0x5611d30306f3 0x5611d30fa4c2 0x5611d30fa83d 0x5611d30fa6e6 0x5611d30d2163\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x5612dafae000 @  0x7fd0146141e7 0x7fd01185946e 0x7fd0118a9c7b 0x7fd0118aa35f 0x7fd01194c103 0x5611d2fc2544 0x5611d2fc2240 0x5611d3036627 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d2fc3afa 0x5611d3031915 0x5611d30309ee 0x5611d2fc3bda 0x5611d3035d00 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d3030ced 0x5611d2fc448c 0x5611d3005159 0x5611d30020a4 0x5611d2fc2d49 0x5611d303694f\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x5613dc898000 @  0x7fd0146141e7 0x7fd01185946e 0x7fd0118a9c7b 0x7fd0118aa35f 0x7fcf9b215235 0x7fcf9ab98792 0x7fcf9ab98d42 0x7fcf9ab51aee 0x5611d2fc2437 0x5611d2fc2240 0x5611d30360f3 0x5611d2fc3afa 0x5611d3031c0d 0x5611d3030ced 0x5611d2f02eb0 0x5611d3032fe4 0x5611d30309ee 0x5611d2fc3bda 0x5611d3031c0d 0x5611d3030ced 0x5611d2fc3bda 0x5611d3031c0d 0x5611d2fc3afa 0x5611d3031c0d 0x5611d30309ee 0x5611d2fc4271 0x5611d2fc4698 0x5611d3032fe4 0x5611d30309ee 0x5611d2fc3bda 0x5611d3031915\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_args\": {\n",
            "    \"func_name\": \"training.networks.G_main\",\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"mapping_layers\": 2,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"D_args\": {\n",
            "    \"func_name\": \"training.networks.D_main\",\n",
            "    \"mbstd_group_size\": 4,\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.0025\n",
            "  },\n",
            "  \"D_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.0025\n",
            "  },\n",
            "  \"loss_args\": {\n",
            "    \"func_name\": \"training.loss.stylegan2\",\n",
            "    \"r1_gamma\": 6.5536\n",
            "  },\n",
            "  \"augment_args\": {\n",
            "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
            "    \"tune_heuristic\": \"rt\",\n",
            "    \"tune_target\": 0.6,\n",
            "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
            "    \"apply_args\": {\n",
            "      \"xflip\": 1,\n",
            "      \"rotate90\": 1,\n",
            "      \"xint\": 1,\n",
            "      \"scale\": 1,\n",
            "      \"rotate\": 1,\n",
            "      \"aniso\": 1,\n",
            "      \"xfrac\": 1,\n",
            "      \"brightness\": 1,\n",
            "      \"contrast\": 1,\n",
            "      \"lumaflip\": 1,\n",
            "      \"hue\": 1,\n",
            "      \"saturation\": 1,\n",
            "      \"imgfilter\": 1,\n",
            "      \"noise\": 1,\n",
            "      \"cutout\": 1\n",
            "    },\n",
            "    \"tune_kimg\": 100\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"train_dataset_args\": {\n",
            "    \"path\": \"./dataset/Img\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"resolution\": 512,\n",
            "    \"mirror_augment\": false\n",
            "  },\n",
            "  \"metric_arg_list\": [\n",
            "    {\n",
            "      \"name\": \"fid50k_full\",\n",
            "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
            "      \"max_reals\": null,\n",
            "      \"num_fakes\": 50000,\n",
            "      \"minibatch_per_gpu\": 8,\n",
            "      \"force_dataset_args\": {\n",
            "        \"shuffle\": false,\n",
            "        \"max_images\": null,\n",
            "        \"repeat\": false,\n",
            "        \"mirror_augment\": false\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"metric_dataset_args\": {\n",
            "    \"path\": \"./dataset/Img\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"resolution\": 512,\n",
            "    \"mirror_augment\": false\n",
            "  },\n",
            "  \"total_kimg\": 10000,\n",
            "  \"minibatch_size\": 8,\n",
            "  \"minibatch_gpu\": 8,\n",
            "  \"G_smoothing_kimg\": 2.5,\n",
            "  \"G_smoothing_rampup\": null,\n",
            "  \"resume_pkl\": \"ffhq.pkl\",\n",
            "  \"run_dir\": \"/content/drive/MyDrive/styleGAN/result/00005-Img-res512-auto1-kimg10000-bgcfnc-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:  /content/drive/MyDrive/styleGAN/result/00005-Img-res512-auto1-kimg10000-bgcfnc-resumecustom\n",
            "Training data:     ./dataset/Img\n",
            "Training length:   10000 kimg\n",
            "Resolution:        512\n",
            "Number of GPUs:    1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x5611daeec000 @  0x7fd014616001 0x7fd01185954f 0x7fd0118a9b58 0x7fd0118adb17 0x7fd01194c203 0x5611d2fc2544 0x5611d2fc2240 0x5611d3036627 0x5611d3030ced 0x5611d2fc448c 0x5611d3005159 0x5611d30020a4 0x5611d2fc2d49 0x5611d303694f 0x5611d30309ee 0x5611d2f02e2b 0x5611d3032fe4 0x5611d30309ee 0x5611d2f02e2b 0x5611d3032fe4 0x5611d3030ced 0x5611d2f02e2b 0x5611d3032fe4 0x5611d2fc3afa 0x5611d3031915 0x5611d30309ee 0x5611d30306f3 0x5611d30fa4c2 0x5611d30fa83d 0x5611d30fa6e6 0x5611d30d2163\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x5614dc898000 @  0x7fd0146141e7 0x7fd01185946e 0x7fd0118a9c7b 0x7fd0118aa35f 0x7fd01194c103 0x5611d2fc2544 0x5611d2fc2240 0x5611d3036627 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d2fc3afa 0x5611d3031915 0x5611d30309ee 0x5611d2fc3bda 0x5611d3035d00 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d3030ced 0x5611d2fc448c 0x5611d3005159 0x5611d30020a4 0x5611d2fc2d49 0x5611d303694f\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x5614dc898000 @  0x7fd0146141e7 0x7fd01185946e 0x7fd0118a9c7b 0x7fd0118aa35f 0x7fcf9b215235 0x7fcf9ab98792 0x7fcf9ab98d42 0x7fcf9ab51aee 0x5611d2fc2437 0x5611d2fc2240 0x5611d30360f3 0x5611d2fc3afa 0x5611d3031c0d 0x5611d3030ced 0x5611d2f02eb0 0x5611d3032fe4 0x5611d30309ee 0x5611d2fc3bda 0x5611d3031c0d 0x5611d3030ced 0x5611d2fc3bda 0x5611d3031c0d 0x5611d2fc3afa 0x5611d3031c0d 0x5611d30309ee 0x5611d2fc4271 0x5611d2fc4698 0x5611d3032fe4 0x5611d30309ee 0x5611d2fc3bda 0x5611d3031915\n",
            "Image shape: [3, 512, 512]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
            "Resuming from \"ffhq.pkl\"\n",
            "\n",
            "G                             Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "G_mapping/Normalize           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 16, 512)        -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "Truncation/Lerp               -         (?, 16, 512)        -               \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)   \n",
            "---                           ---       ---                 ---             \n",
            "Total                         28700647                                      \n",
            "\n",
            "\n",
            "D                    Params    OutputShape         WeightShape     \n",
            "---                  ---       ---                 ---             \n",
            "images_in            -         (?, 3, 512, 512)    -               \n",
            "labels_in            -         (?, 0)              -               \n",
            "512x512/FromRGB      256       (?, 64, 512, 512)   (1, 1, 3, 64)   \n",
            "512x512/Conv0        36928     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "512x512/Conv1_down   73856     (?, 128, 256, 256)  (3, 3, 64, 128) \n",
            "512x512/Skip         8192      (?, 128, 256, 256)  (1, 1, 64, 128) \n",
            "256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n",
            "256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n",
            "128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
            "128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
            "64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
            "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
            "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
            "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
            "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
            "Output               513       (?, 1)              (512, 1)        \n",
            "---                  ---       ---                 ---             \n",
            "Total                28982849                                      \n",
            "\n",
            "Exporting sample images...\n",
            "Replicating networks across 1 GPUs...\n",
            "Initializing augmentations...\n",
            "Setting up optimizers...\n",
            "Constructing training graph...\n",
            "Finalizing training ops...\n",
            "Initializing metrics...\n",
            "Training for 10000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 2m 39s       sec/tick 27.1    sec/kimg 846.84  maintenance 131.5  gpumem 9.9   augment 0.000\n",
            "Evaluating metrics...\n",
            "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n",
            "Calculating real image statistics for fid50k_full...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x56176670c000 @  0x7fd014616001 0x7fd01185954f 0x7fd0118a9b58 0x7fd0118adb17 0x7fd01194c203 0x5611d2fc2544 0x5611d2fc2240 0x5611d3036627 0x5611d3030ced 0x5611d2fc448c 0x5611d3005159 0x5611d30020a4 0x5611d2fc2d49 0x5611d303694f 0x5611d30309ee 0x5611d2f02e2b 0x5611d3032fe4 0x5611d2fc3afa 0x5611d3031c0d 0x5611d30b4cf8 0x5611d3031daf 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2f02e2b 0x5611d3032fe4 0x5611d3030ced\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x561891dc4000 @  0x7fd0146141e7 0x7fd01185946e 0x7fd0118a9c7b 0x7fd0118aa35f 0x7fd01194c103 0x5611d2fc2544 0x5611d2fc2240 0x5611d3036627 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d2fc3afa 0x5611d3031915 0x5611d30309ee 0x5611d2fc3bda 0x5611d3035d00 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d3030ced 0x5611d2fc448c 0x5611d3005159 0x5611d30020a4 0x5611d2fc2d49 0x5611d303694f\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x561891dc4000 @  0x7fd0146141e7 0x7fd01185946e 0x7fd0118a9c7b 0x7fd0118aa35f 0x7fcf9b215235 0x7fcf9ab98792 0x7fcf9ab98d42 0x7fcf9ab51aee 0x5611d2fc2437 0x5611d2fc2240 0x5611d30360f3 0x5611d2fc3afa 0x5611d3031c0d 0x5611d3030ced 0x5611d2f02eb0 0x5611d3032fe4 0x5611d30309ee 0x5611d2fc3bda 0x5611d3031c0d 0x5611d3030ced 0x5611d2fc3bda 0x5611d3031c0d 0x5611d2fc3afa 0x5611d3031c0d 0x5611d30309ee 0x5611d2fc4271 0x5611d2fc4698 0x5611d3032fe4 0x5611d30309ee 0x5611d2fc3bda 0x5611d3031915\n",
            "network-snapshot-000000        time 26m 33s      fid50k_full 144.1616\n",
            "tick 1     kimg 4.0      time 47m 32s      sec/tick 1062.0  sec/kimg 265.50  maintenance 1631.9 gpumem 9.9   augment 0.011\n",
            "tick 2     kimg 8.0      time 1h 05m 16s   sec/tick 1063.7  sec/kimg 265.92  maintenance 0.0    gpumem 9.9   augment 0.032\n",
            "tick 3     kimg 12.0     time 1h 23m 03s   sec/tick 1066.5  sec/kimg 266.63  maintenance 0.0    gpumem 9.9   augment 0.047\n",
            "tick 4     kimg 16.0     time 1h 40m 51s   sec/tick 1068.6  sec/kimg 267.16  maintenance 0.0    gpumem 9.9   augment 0.067\n",
            "tick 5     kimg 20.0     time 1h 58m 40s   sec/tick 1069.2  sec/kimg 267.30  maintenance 0.0    gpumem 9.9   augment 0.083\n",
            "tick 6     kimg 24.0     time 2h 16m 31s   sec/tick 1070.0  sec/kimg 267.51  maintenance 0.0    gpumem 9.9   augment 0.092\n",
            "tick 7     kimg 28.0     time 2h 34m 21s   sec/tick 1070.6  sec/kimg 267.64  maintenance 0.0    gpumem 9.9   augment 0.100\n",
            "tick 8     kimg 32.0     time 2h 52m 14s   sec/tick 1072.5  sec/kimg 268.11  maintenance 0.0    gpumem 9.9   augment 0.114\n",
            "tick 9     kimg 36.0     time 3h 10m 06s   sec/tick 1072.0  sec/kimg 268.01  maintenance 0.0    gpumem 9.9   augment 0.118\n",
            "tick 10    kimg 40.0     time 3h 27m 58s   sec/tick 1072.8  sec/kimg 268.19  maintenance 0.0    gpumem 9.9   augment 0.122\n",
            "Evaluating metrics...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x56175fa2c000 @  0x7fd014616001 0x7fd01185954f 0x7fd0118a9b58 0x7fd0118adb17 0x7fd01194c203 0x5611d2fc2544 0x5611d2fc2240 0x5611d3036627 0x5611d3030ced 0x5611d2fc448c 0x5611d3005159 0x5611d30020a4 0x5611d2fc2d49 0x5611d303694f 0x5611d30309ee 0x5611d2f02e2b 0x5611d3032fe4 0x5611d2fc3afa 0x5611d3031c0d 0x5611d2fc3afa 0x5611d3031c0d 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2f02e2b 0x5611d3032fe4 0x5611d3030ced\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x561904cde000 @  0x7fd0146141e7 0x7fd01185946e 0x7fd0118a9c7b 0x7fd0118aa35f 0x7fd01194c103 0x5611d2fc2544 0x5611d2fc2240 0x5611d3036627 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d2fc3afa 0x5611d3031915 0x5611d30309ee 0x5611d2fc3bda 0x5611d3035d00 0x5611d30309ee 0x5611d2fc3bda 0x5611d3032737 0x5611d3030ced 0x5611d2fc448c 0x5611d3005159 0x5611d30020a4 0x5611d2fc2d49 0x5611d303694f\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x561904cde000 @  0x7fd0146141e7 0x7fd01185946e 0x7fd0118a9c7b 0x7fd0118aa35f 0x7fcf9b215235 0x7fcf9ab98792 0x7fcf9ab98d42 0x7fcf9ab51aee 0x5611d2fc2437 0x5611d2fc2240 0x5611d30360f3 0x5611d2fc3afa 0x5611d3031c0d 0x5611d3030ced 0x5611d2f02eb0 0x5611d3032fe4 0x5611d30309ee 0x5611d2fc3bda 0x5611d3031c0d 0x5611d3030ced 0x5611d2fc3bda 0x5611d3031c0d 0x5611d2fc3afa 0x5611d3031c0d 0x5611d30309ee 0x5611d2fc4271 0x5611d2fc4698 0x5611d3032fe4 0x5611d30309ee 0x5611d2fc3bda 0x5611d3031915\n",
            "network-snapshot-000040        time 23m 36s      fid50k_full 20.8504\n",
            "tick 11    kimg 44.0     time 4h 09m 46s   sec/tick 1072.8  sec/kimg 268.21  maintenance 1435.2 gpumem 9.9   augment 0.126\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 561, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 553, in main\n",
            "    run_training(**vars(args))\n",
            "  File \"train.py\", line 451, in run_training\n",
            "    training_loop.training_loop(**training_options)\n",
            "  File \"/content/stylegan2-ada/training/training_loop.py\", line 250, in training_loop\n",
            "    tflib.run([D_train_op, Gs_update_op], {Gs_beta_in: Gs_beta})\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/tfutil.py\", line 33, in run\n",
            "    return tf.get_default_session().run(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l {outdir}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGFzFFhjPoYP",
        "outputId": "70eb61d7-371e-4565-d7c2-6f7bb6d092eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "drwx------ 2 root root 4096 Jan 10 05:02 00003-Img-res512-auto1-bgcfnc-resumecustom\n",
            "drwx------ 2 root root 4096 Jan 16 06:53 00004-Img-res512-auto1-kimg10000-bgcfnc-resumecustom\n",
            "drwx------ 2 root root 4096 Jan 16 11:08 00005-Img-res512-auto1-kimg10000-bgcfnc-resumecustom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l {outdir}/00005-Img-res512-auto1-kimg10000-bgcfnc-resumecustom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86xoQCx7mMbk",
        "outputId": "84e21bad-0ea7-42fd-bd25-4c7ee6ae6ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 834245\n",
            "-rw------- 1 root root     10210 Jan 16 11:03 events.out.tfevents.1642317809.b662e459645e\n",
            "-rw------- 1 root root  40266390 Jan 16 06:56 fakes000000.png\n",
            "-rw------- 1 root root  38725753 Jan 16 10:21 fakes000040.png\n",
            "-rw------- 1 root root  40261998 Jan 16 06:55 fakes_init.png\n",
            "-rw------- 1 root root      7821 Jan 16 11:03 log.txt\n",
            "-rw------- 1 root root       139 Jan 16 10:45 metric-fid50k_full.txt\n",
            "-rw------- 1 root root 351358684 Jan 16 06:56 network-snapshot-000000.pkl\n",
            "-rw------- 1 root root 351358684 Jan 16 10:21 network-snapshot-000040.pkl\n",
            "-rw------- 1 root root  32271619 Jan 16 06:54 reals.png\n",
            "-rw------- 1 root root      2126 Jan 16 06:53 training_options.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "- 코드 작성 및 모델 훈련은 아래의 링크들을 참고하여 진행되었습니다.\n",
        "  - https://medium.com/codex/how-to-train-stylegan2-ada-in-colab-using-instagram-images-7ff552667a20\n",
        "  - https://colab.research.google.com/github/Hephyrius/Stylegan2-Ada-Google-Colab-Starter-Notebook/blob/main/Stylegan2_Ada_Colab_Starter.ipynb#scrollTo=Kp0lejMIAd8i"
      ],
      "metadata": {
        "id": "e75u5COMYYoz"
      }
    }
  ]
}